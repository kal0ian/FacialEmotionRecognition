{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D, TimeDistributed, BatchNormalization, SimpleRNN, Reshape, LSTM, Permute\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    model_json = model.to_json()\n",
    "    with open(filename + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(filename + \".h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_parquet(DATA_FOLDER + \"training.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_public_test = pd.read_parquet(DATA_FOLDER + \"public_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_private_test = pd.read_parquet(DATA_FOLDER + \"private_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x_train = df_training.as_matrix()[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "x_train = df_training.as_matrix()[:,1:]\n",
    "y_train = df_training.as_matrix()[:,0]\n",
    "x_test = df_public_test.as_matrix()[:,1:]\n",
    "y_test = df_public_test.as_matrix()[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 48, 48, 1)\n",
    "x_test = x_test.reshape(-1, 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\")/255.\n",
    "x_test = x_test.astype(\"float32\")/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu',\n",
    "                 input_shape = (48, 48, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Permute((3, 2, 1)))\n",
    "model.add(Reshape((64, 81)))\n",
    "model.add(LSTM(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Reshape((128, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_157 (Conv2D)          (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_155 (Bat (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_158 (Conv2D)          (None, 44, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_156 (Bat (None, 44, 44, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_159 (Conv2D)          (None, 20, 20, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_157 (Bat (None, 20, 20, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_160 (Conv2D)          (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_158 (Bat (None, 18, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "permute_19 (Permute)         (None, 64, 9, 9)          0         \n",
      "_________________________________________________________________\n",
      "reshape_36 (Reshape)         (None, 64, 81)            0         \n",
      "_________________________________________________________________\n",
      "lstm_50 (LSTM)               (None, 256)               346112    \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "reshape_37 (Reshape)         (None, 128, 2)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 460,359\n",
      "Trainable params: 459,847\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(zoom_range = 0.1,\n",
    "                            height_shift_range = 0.1,\n",
    "                            width_shift_range = 0.1,\n",
    "                            rotation_range = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=1e-4), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "500/500 [==============================] - 742s 1s/step - loss: 1.8241 - acc: 0.2542 - val_loss: 1.6952 - val_acc: 0.3375\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 735s 1s/step - loss: 1.7196 - acc: 0.3028 - val_loss: 1.7646 - val_acc: 0.3275\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 746s 1s/step - loss: 1.6701 - acc: 0.3412 - val_loss: 1.6557 - val_acc: 0.3475\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 716s 1s/step - loss: 1.6128 - acc: 0.3639 - val_loss: 1.5729 - val_acc: 0.4000\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 724s 1s/step - loss: 1.5681 - acc: 0.3878 - val_loss: 1.4605 - val_acc: 0.4425\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 759s 2s/step - loss: 1.5427 - acc: 0.4005 - val_loss: 1.3864 - val_acc: 0.4525\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 783s 2s/step - loss: 1.5087 - acc: 0.4108 - val_loss: 1.3632 - val_acc: 0.4900\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 814s 2s/step - loss: 1.4884 - acc: 0.4212 - val_loss: 1.3225 - val_acc: 0.4975\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 738s 1s/step - loss: 1.4622 - acc: 0.4300 - val_loss: 1.3497 - val_acc: 0.4800\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 771s 2s/step - loss: 1.4374 - acc: 0.4503 - val_loss: 1.2744 - val_acc: 0.5175\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 769s 2s/step - loss: 1.3914 - acc: 0.4606 - val_loss: 1.2779 - val_acc: 0.5350\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 747s 1s/step - loss: 1.3868 - acc: 0.4671 - val_loss: 1.2541 - val_acc: 0.5425\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 744s 1s/step - loss: 1.3751 - acc: 0.4664 - val_loss: 1.2290 - val_acc: 0.5750\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 792s 2s/step - loss: 1.3591 - acc: 0.4779 - val_loss: 1.2368 - val_acc: 0.5500\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 719s 1s/step - loss: 1.3525 - acc: 0.4790 - val_loss: 1.2110 - val_acc: 0.5675\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 720s 1s/step - loss: 1.3580 - acc: 0.4724 - val_loss: 1.2104 - val_acc: 0.5650\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 726s 1s/step - loss: 1.3292 - acc: 0.4925 - val_loss: 1.1760 - val_acc: 0.5725\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 737s 1s/step - loss: 1.3301 - acc: 0.4876 - val_loss: 1.2001 - val_acc: 0.5550\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 716s 1s/step - loss: 1.3104 - acc: 0.4966 - val_loss: 1.1833 - val_acc: 0.5400\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 687s 1s/step - loss: 1.3107 - acc: 0.4901 - val_loss: 1.1705 - val_acc: 0.5825\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=16),\n",
    "                           steps_per_epoch=500,\n",
    "                           epochs=20, #Increase this when not on Kaggle kernel\n",
    "                           validation_data=(x_test[:400,:], y_test[:400,:]), #For speed\n",
    "                           callbacks=[annealer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40\n",
      "500/500 [==============================] - 731s 1s/step - loss: 1.2881 - acc: 0.5018 - val_loss: 1.1696 - val_acc: 0.5975\n",
      "Epoch 22/40\n",
      "500/500 [==============================] - 736s 1s/step - loss: 1.2911 - acc: 0.5024 - val_loss: 1.1683 - val_acc: 0.5850\n",
      "Epoch 23/40\n",
      "500/500 [==============================] - 748s 1s/step - loss: 1.2942 - acc: 0.5030 - val_loss: 1.1738 - val_acc: 0.5775\n",
      "Epoch 24/40\n",
      "500/500 [==============================] - 725s 1s/step - loss: 1.2839 - acc: 0.5088 - val_loss: 1.1568 - val_acc: 0.5950\n",
      "Epoch 25/40\n",
      "500/500 [==============================] - 705s 1s/step - loss: 1.2815 - acc: 0.5088 - val_loss: 1.1614 - val_acc: 0.5900\n",
      "Epoch 26/40\n",
      "500/500 [==============================] - 711s 1s/step - loss: 1.2871 - acc: 0.5054 - val_loss: 1.1535 - val_acc: 0.5975\n",
      "Epoch 27/40\n",
      "500/500 [==============================] - 707s 1s/step - loss: 1.2705 - acc: 0.5098 - val_loss: 1.1504 - val_acc: 0.6000\n",
      "Epoch 28/40\n",
      "500/500 [==============================] - 710s 1s/step - loss: 1.2536 - acc: 0.5153 - val_loss: 1.1514 - val_acc: 0.5900\n",
      "Epoch 29/40\n",
      "500/500 [==============================] - 706s 1s/step - loss: 1.2750 - acc: 0.5110 - val_loss: 1.1500 - val_acc: 0.6000\n",
      "Epoch 30/40\n",
      "500/500 [==============================] - 704s 1s/step - loss: 1.2528 - acc: 0.5164 - val_loss: 1.1449 - val_acc: 0.5900\n",
      "Epoch 31/40\n",
      "500/500 [==============================] - 707s 1s/step - loss: 1.2663 - acc: 0.5119 - val_loss: 1.1439 - val_acc: 0.5875\n",
      "Epoch 32/40\n",
      "500/500 [==============================] - 707s 1s/step - loss: 1.2551 - acc: 0.5184 - val_loss: 1.1409 - val_acc: 0.5925\n",
      "Epoch 33/40\n",
      "500/500 [==============================] - 709s 1s/step - loss: 1.2493 - acc: 0.5208 - val_loss: 1.1349 - val_acc: 0.5875\n",
      "Epoch 34/40\n",
      "500/500 [==============================] - 706s 1s/step - loss: 1.2544 - acc: 0.5159 - val_loss: 1.1328 - val_acc: 0.5925\n",
      "Epoch 35/40\n",
      "500/500 [==============================] - 751s 2s/step - loss: 1.2376 - acc: 0.5282 - val_loss: 1.1264 - val_acc: 0.5950\n",
      "Epoch 36/40\n",
      "500/500 [==============================] - 718s 1s/step - loss: 1.2460 - acc: 0.5200 - val_loss: 1.1255 - val_acc: 0.5975\n",
      "Epoch 37/40\n",
      "500/500 [==============================] - 716s 1s/step - loss: 1.2632 - acc: 0.5116 - val_loss: 1.1239 - val_acc: 0.5850\n",
      "Epoch 38/40\n",
      "500/500 [==============================] - 716s 1s/step - loss: 1.2235 - acc: 0.5317 - val_loss: 1.1246 - val_acc: 0.5900\n",
      "Epoch 39/40\n",
      "500/500 [==============================] - 710s 1s/step - loss: 1.2536 - acc: 0.5162 - val_loss: 1.1278 - val_acc: 0.5850\n",
      "Epoch 40/40\n",
      "500/500 [==============================] - 704s 1s/step - loss: 1.2540 - acc: 0.5208 - val_loss: 1.1331 - val_acc: 0.5750\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=16),\n",
    "                           steps_per_epoch=500,\n",
    "                           initial_epoch=20,\n",
    "                           epochs=40, #Increase this when not on Kaggle kernel\n",
    "                           validation_data=(x_test[:400,:], y_test[:400,:]), #For speed\n",
    "                           callbacks=[annealer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_loss, final_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "save_model(model, \"./trained_models/elena_model1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
